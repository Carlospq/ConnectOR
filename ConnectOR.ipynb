{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ConectOR (Conect Orthologue RNAs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### IMPORTS\n",
    "import re\n",
    "import subprocess\n",
    "import os, sys\n",
    "import fileinput\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "import json\n",
    "import wget\n",
    "import gzip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "### VARIABLES\n",
    "# minMatch liftOver required to mapp to new region\n",
    "try:\n",
    "    minMatch=sys.argv[1]\n",
    "except IndexError:\n",
    "    minMatch=50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### FUNCTIONS\n",
    "\n",
    "def read_config(file_name):\n",
    "    config_df =  pd.read_csv(file_name, sep='\\t', na_filter= False)\n",
    "    return(config_df)\n",
    "\n",
    "def check_folder(folder_name):\n",
    "    if not os.path.exists(folder_name):\n",
    "        os.makedirs(folder_name)\n",
    "\n",
    "def check_file(file_name_list):\n",
    "    for file_name in file_name_list:\n",
    "        if not os.path.isfile(file_name):\n",
    "            print(\"'%s' doesn not exist. Please check config_file. Exiting...\"%(file_name))\n",
    "            sys.exit(1)\n",
    "        \n",
    "def download_default_files(file_url, folder_name):\n",
    "    check_folder(folder_name)\n",
    "    file_name = file_url.split(\"/\")[-1]\n",
    "    if not os.path.isfile(\"/\".join([folder_name, file_name])):\n",
    "        wget.download(file_url, folder_name)\n",
    "        print('\\t%s downloaded succesfully..'%(file_name))\n",
    "    else:\n",
    "        print('\\t%s already exists.. Skipping'%(file_name))\n",
    "    \n",
    "def arguments_dic(line):\n",
    "    args = line[-1].split(\";\")\n",
    "    dic = {}\n",
    "    for e in args:\n",
    "        if e == \";\": continue\n",
    "        if e == \"\": continue\n",
    "        if e[0] == \" \": e = e[1:]\n",
    "        key = e.split(\" \")[0].replace(\"\\\"\",\"\")\n",
    "        dic[key] = e.split(\" \")[1].replace(\"\\\"\",\"\")\n",
    "    return dic\n",
    "\n",
    "def generate_maps(gtf, sp):\n",
    "    \n",
    "    if gtf.endswith(\".gz\"):\n",
    "        f = gzip.open(gtf, 'rb')\n",
    "        compressed = True\n",
    "    else:\n",
    "        f = open(gtf, 'r')\n",
    "        compressed = False\n",
    "        \n",
    "    transcripts = {}\n",
    "    genes = {}\n",
    "\n",
    "    for line in f:\n",
    "        if compressed: line = str(line, 'utf-8')\n",
    "        if line.startswith(\"#\"): continue\n",
    "        line = line.strip().split(\"\\t\")\n",
    "        arguments = arguments_dic(line)\n",
    "\n",
    "        if \"gene_name\" in arguments:\n",
    "            gene_name = arguments[\"gene_name\"]\n",
    "        else:\n",
    "            gene_name = arguments[\"gene_id\"]\n",
    "            \n",
    "        gene_biotype = biotype([\"gene_type\", \"gene_biotype\"], arguments)\n",
    "        if line[2] == \"transcript\":\n",
    "            transcripts[arguments[\"transcript_id\"]] = {\"gene_id\": arguments[\"gene_id\"],\n",
    "                                                       \"gene_type\": gene_biotype,\n",
    "                                                       \"gene_name\": gene_name}\n",
    "            if arguments[\"gene_id\"] in genes:\n",
    "                if genes[arguments[\"gene_id\"]][\"gene_type\"] == \"protein_coding\":\n",
    "                    gene_biotype = \"protein_coding\"\n",
    "            genes[arguments[\"gene_id\"]] = {\"gene_type\": gene_biotype,\n",
    "                                           \"gene_name\": gene_name}\n",
    "            \n",
    "    fo1 = open(\"maps/\"+sp+\".transcriptID_geneID_map.txt\", 'w')\n",
    "    for t in transcripts:\n",
    "        line = \"\\t\".join([t, transcripts[t][\"gene_id\"], transcripts[t][\"gene_name\"], transcripts[t][\"gene_type\"]])\n",
    "        fo1.write(line+\"\\n\")\n",
    "    fo1.close()\n",
    "    \n",
    "    if len(genes) > 0:\n",
    "        fo2 = open(\"maps/\"+sp+\".geneID_geneName_geneType_map.txt\", 'w')\n",
    "        for g in genes:\n",
    "            line = \"\\t\".join([g, genes[g][\"gene_name\"], genes[g][\"gene_type\"]])\n",
    "            fo2.write(line+\"\\n\")\n",
    "        fo2.close()\n",
    "    \n",
    "def biotype(keys, arguments):\n",
    "    biotype=''\n",
    "    while not biotype:\n",
    "        for k in keys:\n",
    "            try:\n",
    "                biotype = arguments[k]\n",
    "                return(biotype)\n",
    "            except KeyError:\n",
    "                pass\n",
    "        if not biotype: biotype = \"NOVEL\"\n",
    "        return(biotype)\n",
    "    \n",
    "def generate_beds(gtf, sp):\n",
    "    \n",
    "    if gtf.endswith(\".gz\"):\n",
    "        f = gzip.open(gtf, 'rb')\n",
    "        compressed = True\n",
    "    else:\n",
    "        f = open(gtf_file, 'r')\n",
    "        compressed = False\n",
    "        \n",
    "    transcripts = {}\n",
    "    genes = {}\n",
    "\n",
    "    output_exons = open(\"./BEDs/{}.exons.bed\".format(sp),\"w\")\n",
    "    for line in f:\n",
    "        if compressed: line = str(line, 'utf-8')\n",
    "        if line.startswith(\"#\"): continue\n",
    "\n",
    "        if line.startswith(\"#\"): continue\n",
    "        line = line.strip().split(\"\\t\")\n",
    "\n",
    "        if line[2] != \"exon\": continue\n",
    "        arguments = arguments_dic(line)\n",
    "\n",
    "        g_id = arguments[\"gene_id\"]\n",
    "        chrom = line[0] if line[0].startswith(\"chr\") else \"chr\"+line[0]\n",
    "        start = str(int(line[3])-1)\n",
    "        end = line[4]\n",
    "        strand = line[6]\n",
    "        if not g_id in genes:\n",
    "            genes[g_id] = {\"chrom\": chrom, \n",
    "                           \"start\": int(start),\n",
    "                           \"end\": int(end),\n",
    "                           \"strand\": strand,\n",
    "                           \"gene_name\": \"\"}\n",
    "        else:\n",
    "            if int(start) < genes[g_id][\"start\"]:\n",
    "                genes[g_id][\"start\"] = int(start)\n",
    "            if int(end) > genes[g_id][\"end\"]:\n",
    "                genes[g_id][\"end\"] = int(end)\n",
    "\n",
    "        if \"gene_name\" in arguments:\n",
    "            genes[g_id][\"gene_name\"] = arguments[\"gene_name\"]\n",
    "        else:\n",
    "            genes[g_id][\"gene_name\"] = arguments[\"gene_id\"]\n",
    "\n",
    "        exon_bed_line = \"\\t\".join([chrom, start, end, genes[g_id][\"gene_name\"], '0', strand])+\"\\n\"\n",
    "        output_exons.write(exon_bed_line)\n",
    "    output_exons.close()\n",
    "    \n",
    "    output_genes = open(\"./BEDs/{}.genes.bed\".format(sp),\"w\")\n",
    "    for gene in genes:\n",
    "        d = genes[gene]\n",
    "        chrom = d[\"chrom\"]\n",
    "        start = str(d[\"start\"])\n",
    "        end = str(d[\"end\"])\n",
    "        strand = d[\"strand\"]\n",
    "        gene_name = d[\"gene_name\"]\n",
    "\n",
    "        gene_bed_line = \"\\t\".join([chrom, start, end, gene_name, '0', strand])+\"\\n\"\n",
    "        output_genes.write(gene_bed_line)\n",
    "    output_genes.close()\n",
    "        \n",
    "def bed_sort(sp_v):\n",
    "    files = [\"./BEDs/{}.exons.bed\".format(sp_v), \"./BEDs/{}.genes.bed\".format(sp_v)]\n",
    "    for file_name in files:\n",
    "        print(\"\\r\\t\"+file_name+\"... sorting\", end=\"\")\n",
    "        call = \"sort -u -k1,1 -k2,2n -o '%s' '%s'\"%(file_name,file_name)    \n",
    "        subprocess.call(call, shell=True)\n",
    "        print(\"\\r\\t\"+file_name+\"... sorted \")\n",
    "        \n",
    "def gene_map_to_dict(file_name):\n",
    "    d = {}\n",
    "    finput = fileinput.FileInput(files=file_name)\n",
    "    for line in finput:\n",
    "        line = line.strip().split(\"\\t\")\n",
    "        d[line[1]] = {\"gene_id\": line[0],\n",
    "                      \"gene_name\": line[1],\n",
    "                      \"gene_type\": line[2]}\n",
    "    finput.close()\n",
    "    return(d)\n",
    "\n",
    "def transcript_map_to_dict(file_name, dl = \"\\t\"):\n",
    "    df = dict(pd.read_csv(file_name, delimiter = dl))\n",
    "    return(df)\n",
    "\n",
    "def parse_orthologs(line):\n",
    "    geneM = line[0]\n",
    "    ortho = line[1].split(\",\")\n",
    "    nexon = line[2].split(\",\")\n",
    "    pcent = line[3].split(\",\")\n",
    "    btype = line[4].split(\",\")\n",
    "\n",
    "    return(geneM, ortho, nexon, pcent, btype)\n",
    "\n",
    "def count_classes(btype):\n",
    "    tmp = []\n",
    "    for type_ in btype:\n",
    "        if type_ in none:\n",
    "            tmp.append(\"none\")\n",
    "        elif type_ in stringtie:\n",
    "            tmp.append(\"stringtie\")\n",
    "        elif type_ in lncRNA:\n",
    "            tmp.append(\"lncRNA\")\n",
    "        elif type_ in sncRNA:\n",
    "            tmp.append(\"sncRNA\")\n",
    "        elif type_ in pc:\n",
    "            tmp.append(\"pc\")\n",
    "        else:\n",
    "            tmp.append(\"other\")\n",
    "    class_ = [tmp.count(\"none\"), tmp.count(\"lncRNA\"), tmp.count(\"sncRNA\"), tmp.count(\"pc\"), tmp.count(\"other\"), tmp.count(\"stringtie\")]\n",
    "\n",
    "    return(class_)\n",
    "\n",
    "def classification(classes):\n",
    "    c = \"other\"\n",
    "    #unique cases\n",
    "    #  none \t\t\t lncRNA \t\t   sncRNA \t\t\t pc \t\t\t   other \t\t\t stringtie\n",
    "    if classes[0]==1 and classes[1]==0 and classes[2]==0 and classes[3]==0 and classes[4]==0 and classes[5]==0:\n",
    "        c = \"none\"\n",
    "    if classes[0]>=0 and classes[1]==1 and classes[2]==0 and classes[3]==0 and classes[4]==0 and classes[5]==0:\n",
    "        c = \"lncRNA\"\n",
    "    if classes[0]>=0 and classes[1]==0 and classes[2]==1 and classes[3]==0 and classes[4]==0 and classes[5]==0:\n",
    "        c = \"sncRNA\"\n",
    "    if classes[0]>=0 and classes[1]==0 and classes[2]==0 and classes[3]==1 and classes[4]==0 and classes[5]==0:\n",
    "        c = \"pc\"\n",
    "    if classes[0]>=0 and classes[1]==0 and classes[2]==0 and classes[3]==0 and classes[4]==1 and classes[5]==0:\n",
    "        c = \"other\"\n",
    "    if classes[0]>=0 and classes[1]==0 and classes[2]==0 and classes[3]==0 and classes[4]==0 and classes[5]>0:\n",
    "        c = \"stringtie\"\n",
    "\n",
    "    #multiple cases\n",
    "    #  none \t\t\t lncRNA \t\t   sncRNA \t\t\t pc \t\t\t  others\t\t\tstringtie\n",
    "    if classes[0]>1 and classes[1]==0 and classes[2]==0 and classes[3]==0 and classes[4]==0 and classes[5]==0:\n",
    "        c = \"nones\"\n",
    "    if classes[0]>=0 and classes[1]>1 and classes[2]==0 and classes[3]==0 and classes[4]==0 and classes[5]==0:\n",
    "        c = \"lncRNAs\"\n",
    "    if classes[0]>=0 and classes[1]==0 and classes[2]>1 and classes[3]==0 and classes[4]==0 and classes[5]==0:\n",
    "        c = \"sncRNAs\"\n",
    "    if classes[0]>=0 and classes[1]==0 and classes[2]==0 and classes[3]>1 and classes[4]==0 and classes[5]==0:\n",
    "        c = \"pcs\"\n",
    "    if classes[0]>=0 and classes[1]==0 and classes[2]==0 and classes[3]==0 and classes[4]>1:\n",
    "        c = \"others\"\n",
    "\n",
    "    #dual cases\n",
    "    #  none \t\t\t lncRNA \t\t   sncRNA \t\t\t pc \t\t\t   other\n",
    "    if classes[0]>=0 and classes[1]>=1 and classes[2]>=1 and classes[3]==0 and classes[4]==0 and classes[5]==0:\n",
    "        c = \"lncRNA_sncRNA\"\n",
    "    if classes[0]>=0 and classes[1]>=1 and classes[2]==0 and classes[3]==0 and classes[4]==0 and classes[5]>=1:\n",
    "        c = \"lncRNA_stringtie\"\n",
    "    if classes[0]>=0 and classes[1]>=1 and classes[2]==0 and classes[3]>=1 and classes[4]==0 and classes[5]==0:\n",
    "        c = \"lncRNA_PC\"\n",
    "    if classes[0]>=0 and classes[1]>=1 and classes[2]==0 and classes[3]==1 and classes[4]>=1 and classes[5]==0:\n",
    "        c = \"lncRNA_other\"\n",
    "    if classes[0]>=0 and classes[1]>=1 and classes[2]==0 and classes[3]>=1 and classes[4]==0 and classes[5]==0:\n",
    "        c = \"lncRNA_PC\"\n",
    "\n",
    "    return(c)\n",
    "\n",
    "def change_default(feature, value):\n",
    "    default_values = config_df.loc[i][\"default\"].split(\"|\")\n",
    "    if feature == \"gtf\": \n",
    "        n = 0\n",
    "    else:\n",
    "        n = 1\n",
    "    default_values[n] = value\n",
    "    return(\"|\".join(default_values))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dictionaries:  ['gtfs', 'gtfs_ensembl_r98', 'chain_maps'] \n",
      "\n",
      "gtfs ['hg38', 'hg19', 'mm10']\n",
      "gtfs_ensembl_r98 ['mm10', 'danrer11', 'hg19', 'hg38']\n",
      "chain_maps ['hg38', 'hg19', 'mm10', 'danrer11', 'danrer10']\n",
      "{'hg38': 'https://hgdownload.soe.ucsc.edu/goldenPath/danRer10/liftOver/danRer10ToHg38.over.chain.gz', 'mm10': 'https://hgdownload.soe.ucsc.edu/goldenPath/danRer10/liftOver/danRer10ToMm10.over.chain.gz'}\n"
     ]
    }
   ],
   "source": [
    "### Dictionaris\n",
    "with open('dictionaries.json') as f:\n",
    "  dictionaries = json.load(f)\n",
    "\n",
    "print(\"dictionaries: \", list(dictionaries.keys()), \"\\n\")\n",
    "for k in dictionaries:\n",
    "    print(k, list(dictionaries[k].keys()))\n",
    "    \n",
    "print(dictionaries[\"chain_maps\"][\"danrer10\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read config file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>assembly_version</th>\n",
       "      <th>annotation</th>\n",
       "      <th>chainmap</th>\n",
       "      <th>default</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>specie</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Human</th>\n",
       "      <td>hg38</td>\n",
       "      <td>/data/projects/p283_rna_and_disease/projects/c...</td>\n",
       "      <td>chainmaps/hg38ToMm10.over.chain.gz,chainmaps/h...</td>\n",
       "      <td>False|True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mouse</th>\n",
       "      <td>mm10</td>\n",
       "      <td>/data/projects/p283_rna_and_disease/projects/c...</td>\n",
       "      <td>chainmaps/mm10ToHg38.over.chain.gz,chainmaps/m...</td>\n",
       "      <td>False|True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZebraFish</th>\n",
       "      <td>danrer10</td>\n",
       "      <td>/data/projects/p283_rna_and_disease/projects/c...</td>\n",
       "      <td>chainmaps/danRer10ToHg38.over.chain.gz,chainma...</td>\n",
       "      <td>False|True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          assembly_version                                         annotation  \\\n",
       "specie                                                                          \n",
       "Human                 hg38  /data/projects/p283_rna_and_disease/projects/c...   \n",
       "Mouse                 mm10  /data/projects/p283_rna_and_disease/projects/c...   \n",
       "ZebraFish         danrer10  /data/projects/p283_rna_and_disease/projects/c...   \n",
       "\n",
       "                                                    chainmap     default  \n",
       "specie                                                                    \n",
       "Human      chainmaps/hg38ToMm10.over.chain.gz,chainmaps/h...  False|True  \n",
       "Mouse      chainmaps/mm10ToHg38.over.chain.gz,chainmaps/m...  False|True  \n",
       "ZebraFish  chainmaps/danRer10ToHg38.over.chain.gz,chainma...  False|True  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config_df = read_config(\"./config\")\n",
    "config_df.set_index(\"specie\", inplace = True)\n",
    "config_df[\"default\"] = \"False|False\"\n",
    "for i in config_df.index:\n",
    "    if not config_df.loc[i][\"annotation\"]:\n",
    "        default_gtf = dictionaries[\"gtfs_ensembl_r98\"][config_df.loc[i][\"assembly_version\"].lower()].split(\"/\")[-1]\n",
    "        config_df.at[i, 'default'] = change_default(\"gtf\", \"True\")\n",
    "        config_df.at[i, 'annotation'] = default_gtf\n",
    "    if not config_df.loc[i][\"chainmap\"]:\n",
    "        chainmaps = []\n",
    "        config_df.at[i, 'default'] = change_default(\"chainmap\", \"True\")\n",
    "        for j in config_df.index:\n",
    "            if i!=j:        \n",
    "                default_chainmap_path = dictionaries[\"chain_maps\"][config_df.loc[i][\"assembly_version\"].lower()][config_df.loc[j][\"assembly_version\"].lower()]\n",
    "                default_chainmap_name = \"chainmaps/\"+default_chainmap_path.split(\"/\")[-1]\n",
    "                chainmaps.append(default_chainmap_name)\n",
    "        config_df.at[i, 'chainmap'] = \",\".join(chainmaps)\n",
    "config_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check config file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking Config_file...\n",
      "\thg38ToMm10.over.chain.gz already exists.. Skipping\n",
      "\thg38ToDanRer10.over.chain.gz already exists.. Skipping\n",
      "\tmm10ToHg38.over.chain.gz already exists.. Skipping\n",
      "\tmm10ToDanRer10.over.chain.gz already exists.. Skipping\n",
      "\tdanRer10ToHg38.over.chain.gz already exists.. Skipping\n",
      "\tdanRer10ToMm10.over.chain.gz already exists.. Skipping\n",
      "Config_file is correct..\n"
     ]
    }
   ],
   "source": [
    "print(\"Checking Config_file...\")\n",
    "for i in config_df.index:\n",
    "    if not config_df.loc[i][\"assembly_version\"].lower() in dictionaries[\"chain_maps\"]:\n",
    "        print(\"'%s' is not a valid assembly_version. Please use one of the following values for default analysis: %s\"%(config_df.loc[i][\"assembly_version\"], \",\".join(dictionaries[\"chain_maps\"])))\n",
    "        sys.exit(1)\n",
    "    \n",
    "    defaults = config_df.loc[i][\"default\"].split(\"|\")\n",
    "    #Check GTFs and chainmaps\n",
    "    for feature,default in zip([\"annotation\",\"chainmap\"],defaults):\n",
    "        sp_vi = config_df.loc[i][\"assembly_version\"].lower()\n",
    "        if default == \"True\":\n",
    "            if feature == \"GTFs\": download_default_files(dictionaries[\"gtfs_ensembl_r98\"][sp_vi], \"GTFs\")\n",
    "            if feature == \"chainmap\":\n",
    "                for j in config_df.index:\n",
    "                    if i == j: continue\n",
    "                    sp_vj = config_df.loc[j][\"assembly_version\"].lower()\n",
    "                    url=dictionaries[\"chain_maps\"][sp_vi][sp_vj]\n",
    "                    download_default_files(url, \"chainmaps\")\n",
    "        else:\n",
    "            if feature == \"annotation\": check_file([config_df.loc[i][feature]])\n",
    "            if feature == \"chainmap\":   check_file(config_df.loc[i][feature].split(\",\"))\n",
    "print(\"Config_file is correct..\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download GTF files (if no gtf provided in config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading GTFs\n",
      "\tNo default GTF needed for Human.. Skipping\n",
      "\tNo default GTF needed for Mouse.. Skipping\n",
      "\tNo default GTF needed for ZebraFish.. Skipping\n"
     ]
    }
   ],
   "source": [
    "print('Downloading GTFs')\n",
    "for i in config_df.index:\n",
    "    if config_df.loc[i][\"default\"].split(\"|\")[0] == \"False\": \n",
    "        print(\"\\tNo default GTF needed for %s.. Skipping\"%(i))\n",
    "        continue    \n",
    "    sp_v = config_df.loc[i][\"assembly_version\"].lower()\n",
    "    download_default_files(dictionaries[\"gtfs_ensembl_r98\"][sp_v], \"GTFs\")        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download chainmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading default chainmaps...\n",
      "\thg38ToMm10.over.chain.gz already exists.. Skipping\n",
      "\thg38ToDanRer10.over.chain.gz already exists.. Skipping\n",
      "\tmm10ToHg38.over.chain.gz already exists.. Skipping\n",
      "\tmm10ToDanRer10.over.chain.gz already exists.. Skipping\n",
      "\tdanRer10ToHg38.over.chain.gz already exists.. Skipping\n",
      "\tdanRer10ToMm10.over.chain.gz already exists.. Skipping\n"
     ]
    }
   ],
   "source": [
    "print('Downloading default chainmaps...')\n",
    "for i in config_df.index:\n",
    "    if config_df.loc[i][\"default\"].split(\"|\")[1] == \"True\":\n",
    "        sp_vi = config_df.loc[i][\"assembly_version\"].lower()\n",
    "        for j in config_df.index:\n",
    "            if i == j: continue\n",
    "            sp_vj = config_df.loc[j][\"assembly_version\"].lower()\n",
    "            url=dictionaries[\"chain_maps\"][sp_vi][sp_vj]\n",
    "            download_default_files(url, \"chainmaps\")\n",
    "    else:\n",
    "        print(\"\\tNo default chainmaps needed for %s.. Skipping\"%(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate maps (transcriptID-geneID & geneID-geneName-geneType) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating transcriptID-geneID & geneID-geneName-geneType maps...\n",
      "\t/data/projects/p283_rna_and_disease/projects/carlos/ConnectOR.v0.01/GTFs/hg38.gtf\n",
      "\t/data/projects/p283_rna_and_disease/projects/carlos/ConnectOR.v0.01/GTFs/mm10.gtf\n",
      "\t/data/projects/p283_rna_and_disease/projects/carlos/ConnectOR.v0.01/GTFs/danrer10.gtf\n"
     ]
    }
   ],
   "source": [
    "check_folder(\"maps\")\n",
    "print(\"Generating transcriptID-geneID & geneID-geneName-geneType maps...\")\n",
    "for i in config_df.index:\n",
    "    gtf_file = config_df.loc[i][\"annotation\"]\n",
    "    sp_v = config_df.loc[i][\"assembly_version\"].lower()\n",
    "    if config_df.loc[i][\"default\"].split(\"|\")[0] == \"True\":\n",
    "        gtf_file = \"GTFs/\"+gtf_file\n",
    "    print(\"\\t\"+gtf_file)\n",
    "    generate_maps(gtf_file, sp_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcripts map:\n",
      "NONHSAT148173.1\tNONHSAT148173.1\tNONHSAT148173.1\tlincRNA\n",
      "NONHSAG000001.2\tNONHSAG000001.2\tNONHSAG000001.2\tlincRNA\n",
      "NONHSAT000002.2\tNONHSAT000002.2\tNONHSAT000002.2\tlincRNA\n",
      "NONHSAT000003.2\tNONHSAT000003.2\tNONHSAT000003.2\tlincRNA\n",
      "NONHSAT000004.2\tNONHSAT000004.2\tNONHSAT000004.2\tlincRNA\n",
      "\n",
      "Genes map:\n",
      "NONHSAT148173.1\tNONHSAT148173.1\tlincRNA\n",
      "NONHSAG000001.2\tNONHSAG000001.2\tlincRNA\n",
      "NONHSAT000002.2\tNONHSAT000002.2\tlincRNA\n",
      "NONHSAT000003.2\tNONHSAT000003.2\tlincRNA\n",
      "NONHSAT000004.2\tNONHSAT000004.2\tlincRNA\n"
     ]
    }
   ],
   "source": [
    "print(\"Transcripts map:\")\n",
    "with open(\"maps/hg38.transcriptID_geneID_map.txt\") as transcripts:\n",
    "    head = [next(transcripts) for x in range(5)]\n",
    "for l in head:\n",
    "    print(l.strip())\n",
    "\n",
    "print(\"\\nGenes map:\")\n",
    "with open(\"maps/hg38.geneID_geneName_geneType_map.txt\") as genes:\n",
    "    head = [next(genes) for x in range(5)]\n",
    "for l in head:\n",
    "    print(l.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate BED with genes/exons from GTF files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating BED files for exons and genes...\n",
      "\t/data/projects/p283_rna_and_disease/projects/carlos/ConnectOR.v0.01/GTFs/hg38.gtf\n",
      "\t/data/projects/p283_rna_and_disease/projects/carlos/ConnectOR.v0.01/GTFs/mm10.gtf\n",
      "\t/data/projects/p283_rna_and_disease/projects/carlos/ConnectOR.v0.01/GTFs/danrer10.gtf\n"
     ]
    }
   ],
   "source": [
    "check_folder(\"BEDs\")\n",
    "print(\"Generating BED files for exons and genes...\")\n",
    "for i in config_df.index:\n",
    "    gtf_file = config_df.loc[i][\"annotation\"]\n",
    "    sp_v = config_df.loc[i][\"assembly_version\"].lower()\n",
    "    if config_df.loc[i][\"default\"].split(\"|\")[0] == \"Treu\":\n",
    "        gtf_file = \"GTFs/\"+gtf_file\n",
    "    print(\"\\t\"+gtf_file)\n",
    "    generate_beds(gtf_file, sp_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sorting BED files...\n",
      "\t./BEDs/hg38.exons.bed... sorted \n",
      "\t./BEDs/hg38.genes.bed... sorted \n",
      "\t./BEDs/mm10.exons.bed... sorted \n",
      "\t./BEDs/mm10.genes.bed... sorted \n",
      "\t./BEDs/danrer10.exons.bed... sorted \n",
      "\t./BEDs/danrer10.genes.bed... sorted \n"
     ]
    }
   ],
   "source": [
    "print(\"Sorting BED files...\")\n",
    "for i in config_df.index:\n",
    "    sp_v = config_df.loc[i][\"assembly_version\"].lower()\n",
    "    bed_sort(sp_v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LifOver exons/genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LiftOver...\n",
      "\tHuman exons to Mouse... done   \n",
      "\tHuman genes to Mouse... done   \n",
      "\tHuman exons to ZebraFish... done   \n",
      "\tHuman genes to ZebraFish... done   \n",
      "\tMouse exons to Human... done   \n",
      "\tMouse genes to Human... done   \n",
      "\tMouse exons to ZebraFish... done   \n",
      "\tMouse genes to ZebraFish... done   \n",
      "\tZebraFish exons to Human... done   \n",
      "\tZebraFish genes to Human... done   \n",
      "\tZebraFish exons to Mouse... done   \n",
      "\tZebraFish genes to Mouse... done   \n"
     ]
    }
   ],
   "source": [
    "check_folder(\"liftovers\")\n",
    "features = [\"exons\", \"genes\"]\n",
    "print(\"LiftOver...\")\n",
    "\n",
    "for i in config_df.index:\n",
    "    sp_vi = config_df.loc[i][\"assembly_version\"].lower()\n",
    "    chainmaps = config_df.loc[i][\"chainmap\"].split(\",\")\n",
    "    n=0\n",
    "    for j in config_df.index:\n",
    "        if i == j: continue\n",
    "        sp_vj = config_df.loc[j][\"assembly_version\"].lower()\n",
    "        map_chain = chainmaps[n] if config_df.loc[i][\"default\"] else chainmaps[n]\n",
    "        n+=1\n",
    "        #liftOver oldFile map.chain newFile unMapped\n",
    "        for feature in features:\n",
    "            print(\"\\r\\t{} {} to {}... mapping\".format(i, feature, j), end=\"\")\n",
    "            oldFile = \"BEDs/{}.{}.bed\".format(sp_vi, feature)\n",
    "            newFile = \"liftovers/{}to{}.{}.liftover\".format(sp_vi, sp_vj, feature)\n",
    "            unMapped= \"liftovers/{}to{}.{}.unmapped\".format(sp_vi, sp_vj, feature)\n",
    "            #print(\"./liftOver {} {} {} {}\".format(oldFile, map_chain, newFile, unMapped))\n",
    "            os.system(\"./liftOver -minMatch=0.{} {} {} {} {}\".format(minMatch, oldFile, map_chain, newFile, unMapped))\n",
    "            print(\"\\r\\t{} {} to {}... done   \".format(i, feature, j))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intersect LiftOvers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intersecting LiftOver...\n",
      "\tHuman exons to Mouse... done         \n",
      "\tHuman genes to Mouse... done         \n",
      "\tHuman exons to ZebraFish... done         \n",
      "\tHuman genes to ZebraFish... done         \n",
      "\tMouse exons to Human... done         \n",
      "\tMouse genes to Human... done         \n",
      "\tMouse exons to ZebraFish... done         \n",
      "\tMouse genes to ZebraFish... done         \n",
      "\tZebraFish exons to Human... done         \n",
      "\tZebraFish genes to Human... done         \n",
      "\tZebraFish exons to Mouse... done         \n",
      "\tZebraFish genes to Mouse... done         \n"
     ]
    }
   ],
   "source": [
    "check_folder(\"overlaps\")\n",
    "print(\"Intersecting LiftOver...\")\n",
    "for i in config_df.index:\n",
    "    for j in config_df.index:\n",
    "        if i == j: continue\n",
    "        for f in [\"exons\", \"genes\"]:\n",
    "            print(\"\\r\\t{} {} to {}... intersecting\".format(i, f, j), end=\"\")\n",
    "            sp1=config_df.loc[i][\"assembly_version\"].lower()\n",
    "            sp2=config_df.loc[j][\"assembly_version\"].lower()\n",
    "            lifover_input = 'liftovers/%sto%s.%s.liftover'%(sp1, sp2, f)\n",
    "            bed_input = 'BEDs/%s.%s.bed'%(sp2, f)\n",
    "            output = 'overlaps/%sto%s.%s.overlap'%(sp1, sp2, f)\n",
    "            call = 'intersectBed -wao -s -a %s -b %s > %s'%(lifover_input, bed_input, output)\n",
    "            subprocess.call(call, shell=True, executable='/bin/bash')\n",
    "            print(\"\\r\\t{} {} to {}... done         \".format(i, f, j))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse Overlaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting orthologues...\n",
      "\tHuman exons to Mouse... done               \n",
      "\tHuman genes to Mouse... done               \n",
      "\tHuman exons to ZebraFish... done               \n",
      "\tHuman genes to ZebraFish... done               \n",
      "\tMouse exons to Human... done               \n",
      "\tMouse genes to Human... done               \n",
      "\tMouse exons to ZebraFish... done               \n",
      "\tMouse genes to ZebraFish... done               \n",
      "\tZebraFish exons to Human... done               \n",
      "\tZebraFish genes to Human... done               \n",
      "\tZebraFish exons to Mouse... done               \n",
      "\tZebraFish genes to Mouse... done               \n"
     ]
    }
   ],
   "source": [
    "check_folder(\"orthology\")\n",
    "print(\"Predicting orthologues...\")\n",
    "\n",
    "for i in config_df.index:\n",
    "    for j in config_df.index:\n",
    "        \n",
    "        if i == j: continue\n",
    "        \n",
    "        sp1=config_df.loc[i][\"assembly_version\"].lower()\n",
    "        sp2=config_df.loc[j][\"assembly_version\"].lower()        \n",
    "        \n",
    "        # \"maps/hg38.transcriptID_geneID_map.txt\"\n",
    "        # ENST00000456328\tENSG00000223972\tDDX11L1\ttranscribed_unprocessed_pseudogene\n",
    "        # ENST00000450305\tENSG00000223972\tDDX11L1\ttranscribed_unprocessed_pseudogene\n",
    "        # ENST00000488147\tENSG00000227232\tWASH7P\tunprocessed_pseudogene\n",
    "        # ENST00000619216\tENSG00000278267\tMIR6859-1\tmiRNA\n",
    "        # ENST00000473358\tENSG00000243485\tMIR1302-2HG\tlncRNA\n",
    "\n",
    "        # \"maps/hg38.geneID_geneName_geneType_map.txt\"\n",
    "        # ENSG00000223972\tDDX11L1\ttranscribed_unprocessed_pseudogene\n",
    "        # ENSG00000227232\tWASH7P\tunprocessed_pseudogene\n",
    "        # ENSG00000278267\tMIR6859-1\tmiRNA\n",
    "        # ENSG00000243485\tMIR1302-2HG\tlncRNA\n",
    "        # ENSG00000284332\tMIR1302-2\tmiRNA\n",
    "        \n",
    "        genes = {}\n",
    "        geneID_Name_Type = gene_map_to_dict('maps/%s.geneID_geneName_geneType_map.txt'%(sp2))\n",
    "\n",
    "        for f in [\"exons\", \"genes\"]:\n",
    "            print(\"\\r\\t{} {} to {}... finding orthologues\".format(i, f, j), end=\"\")\n",
    "            overlaps = \"overlaps/%sto%s.%s.overlap\"%(sp1, sp2, f)\n",
    "            for line in open(overlaps, 'r'):\n",
    "                \n",
    "                # read line overlap between sp1 and sp2\n",
    "                line = line.strip().split(\"\\t\")\n",
    "                geneA = line[3]\n",
    "                exonA = \",\".join([line[0], line[1], line[2]])\n",
    "                geneB = line[9]\n",
    "                exonB = \",\".join([line[6], line[7], line[8]])\n",
    "\n",
    "                # calculate overlapping %\n",
    "                lA = int(line[2])-int(line[1])\n",
    "                lB = int(line[8])-int(line[7])\n",
    "                o = int(line[12])\n",
    "\n",
    "                rA = (o*100)/lA\n",
    "                rB = 0 if lB == 0 else (o*100)/lB\n",
    "\n",
    "                # Harmonic mean\n",
    "                try:\n",
    "                    hm = 2/((1/rA)+(1/rB))\n",
    "                except ZeroDivisionError:\n",
    "                    hm = 0\n",
    "\n",
    "                # Gene_Name and Gene_Type from sp2 gene \n",
    "                gene_name = \".\" if geneB == \".\" else geneID_Name_Type[geneB][\"gene_name\"] #not needed so far\n",
    "                geneBtype = \"none\" if geneB == \".\" else geneID_Name_Type[geneB][\"gene_type\"]\n",
    "            \n",
    "                # Add sp1 gene overlaps to dictionary\n",
    "                if not geneA in genes:\n",
    "                    genes[geneA] = {\"overlaps\": [],\n",
    "                                    \"genetype\": [],\n",
    "                                    \"exons\": {}}\n",
    "\n",
    "                if not geneB in genes[geneA][\"overlaps\"]:\n",
    "                    genes[geneA][\"overlaps\"].append(geneB)\n",
    "                    genes[geneA][\"genetype\"].append(geneBtype)\n",
    "\n",
    "                # Add sp1 exon overlaps to dictionary\n",
    "                if not exonA in genes[geneA][\"exons\"]:\n",
    "                    genes[geneA][\"exons\"][exonA] = {}\n",
    "\n",
    "                if not geneB in genes[geneA][\"exons\"][exonA]:\n",
    "                    genes[geneA][\"exons\"][exonA][geneB] = [rA, rB, hm]\n",
    "\n",
    "                # Exon with highr A>b and B>A overlap \n",
    "                # change % of overlap with HM ??\n",
    "                if rA > genes[geneA][\"exons\"][exonA][geneB][0]:\n",
    "                    genes[geneA][\"exons\"][exonA][geneB] = [rA, rB, hm]\n",
    "\n",
    "            # Summarize overlaps into output\n",
    "            output_file = open('orthology/%sto%s.%s'%(sp1, sp2, f), \"w\")\n",
    "            for geneA in genes:\n",
    "                overlaps = genes[geneA][\"overlaps\"]\n",
    "                genetype = genes[geneA][\"genetype\"]\n",
    "                number_of_exons = []\n",
    "                percentageA = []\n",
    "                percentageB = []\n",
    "                for geneB in overlaps:\n",
    "                    n = 0\n",
    "                    mA, mB = 0, 0\n",
    "                    for exon in genes[geneA][\"exons\"]:\n",
    "                        if geneB in genes[geneA][\"exons\"][exon]:\n",
    "                            n+=1\n",
    "                            # %overlap A>B (rA)\n",
    "                            mA+=genes[geneA][\"exons\"][exon][geneB][0]\n",
    "                            mB+=genes[geneA][\"exons\"][exon][geneB][1]\n",
    "                    number_of_exons.append(str(n))\n",
    "                    percentageA.append(str(mA/n))\n",
    "                    percentageA.append(str(mB/n))\n",
    "                \n",
    "                percentageA = [ int(float(x)) for x in percentageA ]\n",
    "                percentageB = [ int(x) for x in percentageB ]\n",
    "                number_of_exons = [ int(x) for x in number_of_exons ]\n",
    "    \n",
    "                percentageA, number_of_exons, overlaps, genetype = zip(*sorted(zip(percentageA, number_of_exons, overlaps, genetype), reverse=True))\n",
    "                percentageA = [ str(x) for x in percentageA ]\n",
    "                number_of_exons = [ str(x) for x in number_of_exons ]\n",
    "                new_line = \"\\t\".join([geneA, \",\".join(overlaps), \",\".join(number_of_exons), \",\".join(percentageA), \",\".join(genetype)])\n",
    "                output_file.write(new_line+\"\\n\")\n",
    "            output_file.close()\n",
    "             \n",
    "            print(\"\\r\\t{} {} to {}... done               \".format(i, f, j))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifying orthologues...\n",
      "\tHuman to Mouse... done       \n",
      "\tHuman to ZebraFish... done       \n",
      "\tMouse to Human... done       \n",
      "\tMouse to ZebraFish... done       \n",
      "\tZebraFish to Human... done       \n",
      "\tZebraFish to Mouse... done       \n"
     ]
    }
   ],
   "source": [
    "##############################Biotypes##############################\n",
    "# none\t\t\t\t\t\t\t\t\tnone\n",
    "# stringtie\t\t\t\t\t\t\t\tnone\n",
    "# protein_coding\t\t\t\t\t\tpc\n",
    "# 3prime_overlapping_ncRNA\t\t\t\tlncRNA\n",
    "# antisense\t\t\t\t\t\t\t\tlncRNA\n",
    "# bidirectional_promoter_lncRNA\t\t\tlncRNA\n",
    "# lincRNA\t\t\t\t\t\t\t\tlncRNA\n",
    "# non_coding\t\t\t\t\t\t\tlncRNA\n",
    "# processed_transcript\t\t\t\t\tlncRNA\n",
    "# sense_intronic\t\t\t\t\t\tlncRNA\n",
    "# sense_overlapping\t\t\t\t\t\tlncRNA\n",
    "# snoRNA\t\t\t\t\t\t\t\tsncRNA\n",
    "# snRNA\t\t\t\t\t\t\t\t\tsncRNA\n",
    "# sRNA\t\t\t\t\t\t\t\t\tsncRNA\n",
    "# misc_RNA\t\t\t\t\t\t\t\tsncRNA\n",
    "# rRNA\t\t\t\t\t\t\t\t\tsncRNA\n",
    "# scaRNA\t\t\t\t\t\t\t\tsncRNA\n",
    "# TEC \t\t\t\t\t\t\t\t\tother\n",
    "# transcribed_processed_pseudogene \t\tother\n",
    "# transcribed_unitary_pseudogene\t\tother\n",
    "# transcribed_unprocessed_pseudogene\tother\n",
    "# TR_C_gene\t\t\t\t\t\t\t\tother\n",
    "# TR_D_gene\t\t\t\t\t\t\t\tother\n",
    "# TR_J_gene\t\t\t\t\t\t\t\tother\n",
    "# TR_J_pseudogene\t\t\t\t\t\tother\n",
    "# TR_V_gene\t\t\t\t\t\t\t\tother\n",
    "# TR_V_pseudogene\t\t\t\t\t\tother\n",
    "# unitary_pseudogene\t\t\t\t\tother\n",
    "# unprocessed_pseudogene\t\t\t\tother\n",
    "# IG_C_gene\t\t\t\t\t\t\t\tother\n",
    "# IG_D_gene\t\t\t\t\t\t\t\tother\n",
    "# IG_J_gene\t\t\t\t\t\t\t\tother\n",
    "# IG_J_pseudogene\t\t\t\t\t\tother\n",
    "# IG_V_gene\t\t\t\t\t\t\t\tother\n",
    "# IG_V_pseudogene\t\t\t\t\t\tother\n",
    "# pseudogene \t\t\t\t\t\t\tother\n",
    "# ribozyme\t\t\t\t\t\t\t\tother\n",
    "# polymorphic_pseudogene\t\t\t\tother\n",
    "# processed_pseudogene \t\t\t\t\tother\n",
    "####################################################################\n",
    "\n",
    "check_folder(\"classification\")\n",
    "print(\"Classifying orthologues...\")\n",
    "\n",
    "for i in config_df.index:\n",
    "    for j in config_df.index:\n",
    "        \n",
    "        if i == j: continue\n",
    "    \n",
    "        print(\"\\r\\t{} to {}... classifying\".format(i, j), end=\"\")\n",
    "        sp1=config_df.loc[i][\"assembly_version\"].lower()\n",
    "        sp2=config_df.loc[j][\"assembly_version\"].lower()  \n",
    "        output_file = open(\"classification/{}to{}.classification\".format(sp1, sp2), 'w')\n",
    "        \n",
    "        exons_orthologs = \"orthology/{}to{}.exons\".format(sp1, sp2)\n",
    "        genes_orthologs = \"orthology/{}to{}.genes\".format(sp1, sp2)\n",
    "\n",
    "        none = [\"none\"]\n",
    "        stringtie = [\"stringtie\"]\n",
    "        pc = [\"protein_coding\"]\n",
    "        lncRNA = [\"3prime_overlapping_ncRNA\", \"antisense\", \"bidirectional_promoter_lncRNA\", \"lincRNA\", \"non_coding\", \"processed_transcript\", \"sense_intronic\", \"sense_overlapping\", \"lncRNA\"]\n",
    "        sncRNA = [\"snoRNA\", \"snRNA\", \"sRNA\", \"misc_RNA\", \"rRNA\", \"scaRNA\", \"miRNA\"]\n",
    "\n",
    "        exons = {}\n",
    "        genes = {}\n",
    "\n",
    "        for line in open(exons_orthologs, 'r'):\n",
    "            line = line.strip().split(\"\\t\")\n",
    "            geneM, ortho, nexon, pcent, btype = parse_orthologs(line)\n",
    "\n",
    "            counts = count_classes(btype)\n",
    "            c = classification(counts)\n",
    "            exons[geneM] = [counts, c, ortho]\n",
    "\n",
    "        for line in open(genes_orthologs, 'r'):\n",
    "            line = line.strip().split(\"\\t\")\n",
    "            geneM, ortho, nexon, pcent, btype = parse_orthologs(line)\n",
    "\n",
    "            counts = count_classes(btype)\n",
    "            c = classification(counts)\n",
    "            genes[geneM] = [counts, c, ortho]\n",
    "\n",
    "        for gene in exons:\n",
    "            e_counts = exons[gene][0]\n",
    "            e_class_ = exons[gene][1]\n",
    "            e_ortho  = exons[gene][2]\n",
    "            try:\n",
    "                g_counts = genes[gene][0]\n",
    "                g_class_ = genes[gene][1]\n",
    "                g_ortho = genes[gene][2]\n",
    "            except KeyError:\n",
    "                g_counts = \".\"\n",
    "                g_class_ = \".\"\n",
    "                g_ortho = \".\"\n",
    "\n",
    "            output_file.write(\"{}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{}\".format(gene, e_class_, g_class_, \";\".join(e_ortho), e_counts, \";\".join(g_ortho), g_counts)+\"\\n\")\n",
    "        output_file.close()\n",
    "        print(\"\\r\\t{} to {}... done       \".format(i, j))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting results...\n",
      "\tHuman to Mouse... done       \n",
      "\tHuman to ZebraFish... done       \n",
      "\tMouse to Human... done       \n",
      "\tMouse to ZebraFish... done       \n",
      "\tZebraFish to Human... done       \n",
      "\tZebraFish to Mouse... done       \n",
      "\tZebraFish to ZebraFish... plotting"
     ]
    }
   ],
   "source": [
    "check_folder(\"plots\")\n",
    "print(\"Plotting results...\")\n",
    "\n",
    "for i in config_df.index:\n",
    "    for j in config_df.index:\n",
    "        print(\"\\r\\t{} to {}... plotting\".format(i, j), end=\"\")\n",
    "        if i == j: continue\n",
    "        sp1 = config_df.loc[i][\"assembly_version\"].lower()\n",
    "        sp2 = config_df.loc[j][\"assembly_version\"].lower() \n",
    "        input_file = \"classification/{}to{}.classification\".format(sp1, sp2)\n",
    "        path = \"./\"\n",
    "        call = 'Rscript plots.R %s %s %s %s'%(input_file, sp1, sp2, path)\n",
    "        #print(call)\n",
    "        print(\"\\r\\t{} to {}... done       \".format(i, j))\n",
    "        subprocess.call(call, shell=True, executable='/bin/bash') \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
