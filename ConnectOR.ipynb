{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# ConectOR (Conect Orthologue RNAs)"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": "### IMPORTS\nimport re\nimport subprocess\nimport os, sys\nimport fileinput\nimport pandas as pd\nfrom io import StringIO\nimport json\nimport wget\nimport gzip\n#from tqdm import tqdm"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": "### VARIABLES\n# minMatch liftOver required to mapp to new region\ntry:\n    minMatch=sys.argv[1]\nexcept IndexError:\n    minMatch=50\n    \n# sys.argv[] does not work properly in jupyter\nminMatch = 50"
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": "### FUNCTIONS\n\ndef read_config(file_name):\n    config_df =  pd.read_csv(file_name, sep='\\t', na_filter= False)\n    return(config_df)\n\n\ndef check_folder(folder_name):\n    if not os.path.exists(folder_name):\n        os.makedirs(folder_name)\n\n        \ndef check_file(file_name_list):\n    for file_name in file_name_list:\n        if not os.path.isfile(file_name):\n            print(\"'%s' doesn not exist. Please check config_file. Exiting...\"%(file_name))\n            sys.exit(1)\n\n            \ndef download_default_files(file_url, folder_name):\n    check_folder(folder_name)\n    file_name = file_url.split(\"/\")[-1]\n    if not os.path.isfile(\"/\".join([folder_name, file_name])):\n        wget.download(file_url, folder_name)\n        print('\\t%s downloaded succesfully..'%(file_name))\n    else:\n        print('\\t%s already exists.. Skipping'%(file_name))\n\n        \ndef arguments_dic(line):\n    args = line[-1].split(\";\")\n    dic = {}\n    for e in args:\n        if e == \";\": continue\n        if e == \"\": continue\n        if e[0] == \" \": e = e[1:]\n        key = e.split(\" \")[0].replace(\"\\\"\",\"\")\n        dic[key] = e.split(\" \")[1].replace(\"\\\"\",\"\")\n    return dic\n\n\ndef generate_maps(gtf, sp):\n    \n    if gtf.endswith(\".gz\"):\n        f = gzip.open(gtf, 'rb')\n        compressed = True\n    else:\n        f = open(gtf, 'r')\n        compressed = False\n        \n    transcripts = {}\n    genes = {}\n\n    for line in f:\n        if compressed: line = str(line, 'utf-8')\n        if line.startswith(\"#\"): continue\n        line = line.strip().split(\"\\t\")\n        arguments = arguments_dic(line)\n\n        if \"gene_name\" in arguments:\n            gene_name = arguments[\"gene_name\"]\n        else:\n            gene_name = arguments[\"gene_id\"]\n            \n        gene_biotype = biotype([\"gene_type\", \"gene_biotype\"], arguments)\n        if line[2] == \"transcript\":\n            transcripts[arguments[\"transcript_id\"]] = {\"gene_id\": arguments[\"gene_id\"],\n                                                       \"gene_type\": gene_biotype,\n                                                       \"gene_name\": gene_name}\n            if arguments[\"gene_id\"] in genes:\n                if genes[arguments[\"gene_id\"]][\"gene_type\"] == \"protein_coding\":\n                    gene_biotype = \"protein_coding\"\n            genes[arguments[\"gene_id\"]] = {\"gene_type\": gene_biotype,\n                                           \"gene_name\": gene_name}\n            \n    fo1 = open(\"maps/\"+sp+\".transcriptID_geneID_map.txt\", 'w')\n    for t in transcripts:\n        line = \"\\t\".join([t, transcripts[t][\"gene_id\"], transcripts[t][\"gene_name\"], transcripts[t][\"gene_type\"]])\n        fo1.write(line+\"\\n\")\n    fo1.close()\n    \n    if len(genes) > 0:\n        fo2 = open(\"maps/\"+sp+\".geneID_geneName_geneType_map.txt\", 'w')\n        for g in genes:\n            line = \"\\t\".join([g, genes[g][\"gene_name\"], genes[g][\"gene_type\"]])\n            fo2.write(line+\"\\n\")\n        fo2.close()\n\n        \ndef biotype(keys, arguments):\n    biotype=''\n    while not biotype:\n        for k in keys:\n            try:\n                biotype = arguments[k]\n                return(biotype)\n            except KeyError:\n                pass\n        if not biotype: biotype = \"NOVEL\"\n        return(biotype)\n\n    \ndef generate_beds(gtf, sp):\n    \n    if gtf.endswith(\".gz\"):\n        f = gzip.open(gtf, 'rb')\n        compressed = True\n    else:\n        f = open(gtf_file, 'r')\n        compressed = False\n        \n    transcripts = {}\n    genes = {}\n\n    output_exons = open(\"./BEDs/{}.exons.bed\".format(sp),\"w\")\n    for line in f:\n        if compressed: line = str(line, 'utf-8')\n        if line.startswith(\"#\"): continue\n        line = line.strip().split(\"\\t\")\n\n        if line[2] != \"exon\": continue\n        arguments = arguments_dic(line)\n\n        g_id = arguments[\"gene_id\"]\n        chrom = line[0] if line[0].startswith(\"chr\") else \"chr\"+line[0]\n        start = str(int(line[3])-1)\n        end = line[4]\n        strand = line[6]\n        if not g_id in genes:\n            genes[g_id] = {\"chrom\": chrom, \n                           \"start\": int(start),\n                           \"end\": int(end),\n                           \"strand\": strand,\n                           \"gene_name\": \"\"}\n        else:\n            if int(start) < genes[g_id][\"start\"]:\n                genes[g_id][\"start\"] = int(start)\n            if int(end) > genes[g_id][\"end\"]:\n                genes[g_id][\"end\"] = int(end)\n\n        if \"gene_name\" in arguments:\n            genes[g_id][\"gene_name\"] = arguments[\"gene_name\"]\n        else:\n            genes[g_id][\"gene_name\"] = arguments[\"gene_id\"]\n\n        exon_bed_line = \"\\t\".join([chrom, start, end, genes[g_id][\"gene_name\"], '0', strand])+\"\\n\"\n        output_exons.write(exon_bed_line)\n    output_exons.close()\n    \n    output_genes = open(\"./BEDs/{}.genes.bed\".format(sp),\"w\")\n    for gene in genes:\n        d = genes[gene]\n        chrom = d[\"chrom\"]\n        start = str(d[\"start\"])\n        end = str(d[\"end\"])\n        strand = d[\"strand\"]\n        gene_name = d[\"gene_name\"]\n\n        gene_bed_line = \"\\t\".join([chrom, start, end, gene_name, '0', strand])+\"\\n\"\n        output_genes.write(gene_bed_line)\n    output_genes.close()\n\n    \ndef bed_sort(sp_v):\n    files = [\"./BEDs/{}.exons.bed\".format(sp_v), \"./BEDs/{}.genes.bed\".format(sp_v)]\n    for file_name in files:\n        print(\"\".join([\"\\r\\t\",file_name,\"... sorting\"]), end = '')\n        call = \"sort -u -k1,1 -k2,2n -4,4 -o '%s' '%s'\"%(file_name,file_name)    \n        subprocess.call(call, shell=True)\n        print(\"\".join([\"\\r\\t\",file_name,\"... sorted \"]))\n    \n\ndef merge_bed(spv):\n    #This functions assumes BED files are sorted\n    files = [\"./BEDs/{}.exons.bed\".format(spv)]\n    genes = {}\n    previous_id = \"\"\n    \n    for file_name in files:\n        print(\"\\r\\t\"+file_name+\"... merging\", end=\"\")\n        for line in open(file_name, 'r'):\n            line=line.strip().split(\"\\t\")\n\n            chrom = line[0]\n            start = line[1]\n            end = line[2]\n            gene_name = line[3]\n            score = line[4]\n            strand = line[5]\n            \n            iexon = [chrom, start, end, gene_name, score, strand]\n            \n            if not gene_name in genes:\n                genes[gene_name] = [iexon]\n                continue\n\n            jexon = genes[gene_name][-1]\n\n            if int(iexon[1]) >= int(jexon[1]) and int(iexon[1]) <= int(jexon[2]):\n                \n                if int(iexon[2]) >= int(jexon[2]):\n                    jexon[2]=iexon[2]\n\n            if int(iexon[1]) > int(jexon[1]) and int(iexon[1]) > int(jexon[2]):\n                if not iexon in genes[gene_name]:\n                    genes[gene_name].append(iexon)\n        \n        output_exons = open(\"./BEDs/{}.exons.bed\".format(spv),\"w\")\n        for gene in genes:\n            for exon in genes[gene]:\n                exon_bed_line = \"\\t\".join(exon)+\"\\n\"\n                output_exons.write(exon_bed_line)\n        output_exons.close()\n        print(\"\\r\\t\"+file_name+\"... merged \")\n        \n        \ndef gene_map_to_dict(file_name):\n    d = {}\n    finput = fileinput.FileInput(files=file_name)\n    for line in finput:\n        line = line.strip().split(\"\\t\")\n        d[line[1]] = {\"gene_id\": line[0],\n                      \"gene_name\": line[1],\n                      \"gene_type\": line[2]}\n    finput.close()\n    return(d)\n\n\ndef transcript_map_to_dict(file_name, dl = \"\\t\"):\n    dict_ = {}\n    with open(file_name, 'r') as f:\n        for line in f:\n            line = line.strip().split(dl)\n            dict_[line[2]] = {\"transcript_ID\": line[0],\n                              \"gene_id\": line[1],\n                              \"gene_type\": line[3]}\n    return(dict_)\n\n\ndef parse_orthologs(line):\n    geneM = line[0]\n    atype = line[1]\n    ortho = line[2].split(\",\")\n    nexon = line[3].split(\",\")\n    pcent = line[4].split(\",\")\n    btype = line[5].split(\",\")\n\n    return(geneM, atype, ortho, nexon, pcent, btype)\n\n\ndef count_classes(btype):\n    tmp = []\n    for type_ in btype:\n        if type_ in none:\n            tmp.append(\"none\")\n        elif type_ in lncRNA:\n            tmp.append(\"lncRNA\")\n        elif type_ in pc:\n            tmp.append(\"pc\")\n        elif type_ in pseudogene:\n            tmp.append(\"pseudogene\")\n        elif type_ in non_lifted:\n            tmp.append(\"non_lifted\")\n        else:\n            tmp.append(\"other\")\n    class_ = [tmp.count(\"none\"), tmp.count(\"lncRNA\"), tmp.count(\"pc\"), tmp.count(\"pseudogene\"), tmp.count(\"other\"), tmp.count(\"non_lifted\")]\n\n    return(class_)\n\n\ndef classification_tree(exon_info, gene_info):\n    #counts=[\"none\", \"lncRNA\", \"pc\", \"pseudogene\", \"other\", \"non_lifted\"]\n    #var0=atype, var1=btype, var2=counts, var3=ortho  \n    exon_dict=dict((\"var{0}\".format(i),x) for i,x in enumerate(exon_info))\n    gene_dict=dict((\"var{0}\".format(i),x) for i,x in enumerate(gene_info))\n\n    e_counts = exon_dict[\"var2\"]\n    g_counts = gene_dict[\"var2\"]\n    if e_counts[5] == \"non_lfted\" and g_counts == \"non_lifted\":\n        prediction = \"non_lifted\"\n    elif e_counts[2] >= 1:\n        prediction = \"pc(h.c.)\"\n    elif e_counts[1] >= 1:\n        prediction = \"lncRNA(h.c.)\"\n    elif g_counts[2] >= 1:\n        prediction = \"pc(l.c.)\"\n    elif g_counts[2] >= 1:\n        prediction = \"lncRNA(l.c.)\"\n    elif g_counts[3] >= 1:\n        prediction = \"pseudogene(l.c.)\"\n    elif g_counts[4] >= 1:\n        prediction = \"other\"\n    elif g_counts[0] >= 1:\n        prediction = \"none\"\n\n    return(prediction)\n\n\ndef classification(classes):\n    c = \"other\"\n    #unique cases\n    #  none \t\t\t lncRNA \t\t   sncRNA \t\t\t pc \t\t\t   other \t\t\t stringtie\n    if classes[0]==1 and classes[1]==0 and classes[2]==0 and classes[3]==0 and classes[4]==0 and classes[5]==0:\n        c = \"none\"\n    if classes[0]>=0 and classes[1]==1 and classes[2]==0 and classes[3]==0 and classes[4]==0 and classes[5]==0:\n        c = \"lncRNA\"\n    if classes[0]>=0 and classes[1]==0 and classes[2]==1 and classes[3]==0 and classes[4]==0 and classes[5]==0:\n        c = \"sncRNA\"\n    if classes[0]>=0 and classes[1]==0 and classes[2]==0 and classes[3]==1 and classes[4]==0 and classes[5]==0:\n        c = \"pc\"\n    if classes[0]>=0 and classes[1]==0 and classes[2]==0 and classes[3]==0 and classes[4]==1 and classes[5]==0:\n        c = \"other\"\n    if classes[0]>=0 and classes[1]==0 and classes[2]==0 and classes[3]==0 and classes[4]==0 and classes[5]>0:\n        c = \"stringtie\"\n\n    #multiple cases\n    #  none \t\t\t lncRNA \t\t   sncRNA \t\t\t pc \t\t\t  others\t\t\tstringtie\n    if classes[0]>1 and classes[1]==0 and classes[2]==0 and classes[3]==0 and classes[4]==0 and classes[5]==0:\n        c = \"nones\"\n    if classes[0]>=0 and classes[1]>1 and classes[2]==0 and classes[3]==0 and classes[4]==0 and classes[5]==0:\n        c = \"lncRNAs\"\n    if classes[0]>=0 and classes[1]==0 and classes[2]>1 and classes[3]==0 and classes[4]==0 and classes[5]==0:\n        c = \"sncRNAs\"\n    if classes[0]>=0 and classes[1]==0 and classes[2]==0 and classes[3]>1 and classes[4]==0 and classes[5]==0:\n        c = \"pcs\"\n    if classes[0]>=0 and classes[1]==0 and classes[2]==0 and classes[3]==0 and classes[4]>1:\n        c = \"others\"\n\n    #dual cases\n    #  none \t\t\t lncRNA \t\t   sncRNA \t\t\t pc \t\t\t   other\n    if classes[0]>=0 and classes[1]>=1 and classes[2]>=1 and classes[3]==0 and classes[4]==0 and classes[5]==0:\n        c = \"lncRNA_sncRNA\"\n    if classes[0]>=0 and classes[1]>=1 and classes[2]==0 and classes[3]==0 and classes[4]==0 and classes[5]>=1:\n        c = \"lncRNA_stringtie\"\n    if classes[0]>=0 and classes[1]>=1 and classes[2]==0 and classes[3]>=1 and classes[4]==0 and classes[5]==0:\n        c = \"lncRNA_pc\"\n    if classes[0]>=0 and classes[1]>=1 and classes[2]==0 and classes[3]==1 and classes[4]>=1 and classes[5]==0:\n        c = \"lncRNA_other\"\n    if classes[0]>=0 and classes[1]>=1 and classes[2]==0 and classes[3]>=1 and classes[4]==0 and classes[5]==0:\n        c = \"lncRNA_pc\"\n\n    return(c)\n\n\ndef change_default(feature, value):\n    default_values = config_df.loc[i][\"default\"].split(\"|\")\n    if feature == \"gtf\": \n        n = 0\n    else:\n        n = 1\n    default_values[n] = value\n    return(\"|\".join(default_values))\n\n\ndef assign_class(df, col_check1 = \"enames\", col_check2 = \"gnames\", col_assign = \"class\"):\n    for index, row in df.iterrows():\n\n        set1 = set(row[col_check1].split(\";\"))\n        set2 = set(row[col_check2].split(\";\"))\n\n        for _set_ in [set1, set2]:\n            if \".\" in _set_:\n                _set_ = _set_.remove(\".\") if len(_set_) > 1 else _set_\n\n        #Defining Class\n        #Sets are equal\n        if (set1 == set2):\n            #Equal one to one\n            if (len(set1)==1) & (len(set2)==1):\n                #Sets are empty (\".\")\n                if (\".\" in set1) & (\".\" in set2):\n                    row[col_assign] = \"class6\"\n                #Sets have same gene_name\n                else:\n                    row[col_assign] = \"class1\"\n            #Equal many to many\n            elif (len(set1)>1) & (len(set2)>1):\n                row[col_assign] = \"class2\"\n        #Sets are different\n        elif (set1 != set2):\n            #One set is == \".\"\n            if ((set1 == {\".\"}) & (set2 != {\".\"})) | ((set1 != {\".\"}) & (set2 == {\".\"})):\n                row[col_assign] = \"class5\"\n            #eclass is subset of gclass\n            if (set1 <= set2) & (not set1 >= set2):\n                row[col_assign] = \"class3\"\n            #eclass is superset of gclas (*should not happen)\n            elif (set1 >= set2) & (not set1 <= set2):\n                print(set1, set2)\n                row[col_assign] = \"class4\"\n\n    return(df)\n\n\n# SUBCLASS\nsubclass = {\"lncRNA lncRNA\":             \"subclass1\",\n            \"lncRNA lncRNAs\":            \"subclass2\",\n            \"lncRNAs lncRNAs\":           \"subclass3\",\n            \"lncRNA_other lncRNA_other\": \"subclass4\",\n            \n            \"pc pc\":                     \"subclass5\",\n            \"pc pcs\":                    \"subclass6\",\n            \"pcs pcs\":                   \"subclass7\",\n            \"pc pc_other\":               \"subclass8\",\n            \"pc_other pc_other\":         \"subclass9\",\n\n            \"lncRNA lncRNA_pc\":          \"subclass10\",\n            \"lncRNAs lncRNA_pc\":         \"subclass11\",\n            \"lncRNA_pc lncRNA_pc\":       \"subclass12\",\n            \n            \"pc lncRNA_pc\":              \"subclass13\",\n            \"pcs lncRNA_pc\":             \"subclass14\",\n            \"pc_other lncRNA_pc\":        \"subclass15\",\n            \n            \"other other\":               \"subclass16\",\n            \"others others\":             \"subclass17\",\n            \"other lncRNA_other\":        \"subclass18\",\n            \"other pc_other\":            \"subclass19\",\n            \n            \"none none\":                 \"subclass20\",\n            \"none lncRNA\":               \"subclass21\",\n            \"none lncRNA_pc\":            \"subclass22\",\n            \"none lncRNAs\":              \"subclass23\",\n            \"none pc\":                   \"subclass24\",\n            \"none pcs\":                  \"subclass25\"}\n\n\ndef assign_subclass(df, sc_dict=subclass, col_check1 = \"eclass\", col_check2 = \"gclass\", col_assign = \"subclass\"):\n    df[col_assign] = df[col_check1] + \" \" + df[col_check2]\n    #df = df.replace({col_assign: sc_dict})\n    return(df)"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": "### Dictionaris\nwith open('dictionaries.json') as f:\n  dictionaries = json.load(f)\n\n# print(\"dictionaries: \", list(dictionaries.keys()), \"\\n\")\n# for k in dictionaries:\n#     print(k, list(dictionaries[k].keys()))\n    \n# print(dictionaries[\"chain_maps\"][\"danrer10\"])"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Read config file"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>assembly_version</th>\n      <th>annotation</th>\n      <th>chainmap</th>\n      <th>default</th>\n    </tr>\n    <tr>\n      <th>specie</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Human38</th>\n      <td>hg38</td>\n      <td>/home/carlos/Documents/ConnectOR/GTFs/hg38.gen...</td>\n      <td>chainmaps/hg38ToMm10.over.chain.gz</td>\n      <td>False|True</td>\n    </tr>\n    <tr>\n      <th>Mouse</th>\n      <td>mm10</td>\n      <td>/home/carlos/Documents/ConnectOR/GTFs/mm10.gen...</td>\n      <td>chainmaps/mm10ToHg38.over.chain.gz</td>\n      <td>False|True</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "        assembly_version                                         annotation  \\\nspecie                                                                        \nHuman38             hg38  /home/carlos/Documents/ConnectOR/GTFs/hg38.gen...   \nMouse               mm10  /home/carlos/Documents/ConnectOR/GTFs/mm10.gen...   \n\n                                   chainmap     default  \nspecie                                                   \nHuman38  chainmaps/hg38ToMm10.over.chain.gz  False|True  \nMouse    chainmaps/mm10ToHg38.over.chain.gz  False|True  "
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": "config_df = read_config(\"./config\")\n#config_df = read_config(\"./config_local\")\nconfig_df.set_index(\"specie\", inplace = True)\nconfig_df[\"default\"] = \"False|False\"\nfor i in config_df.index:\n    if not config_df.loc[i][\"annotation\"]:\n        default_gtf = dictionaries[\"gtfs_ensembl_r98\"][config_df.loc[i][\"assembly_version\"].lower()].split(\"/\")[-1]\n        config_df.at[i, 'default'] = change_default(\"gtf\", \"True\")\n        config_df.at[i, 'annotation'] = default_gtf\n    if not config_df.loc[i][\"chainmap\"]:\n        chainmaps = []\n        config_df.at[i, 'default'] = change_default(\"chainmap\", \"True\")\n        for j in config_df.index:\n            if i!=j:        \n                default_chainmap_path = dictionaries[\"chain_maps\"][config_df.loc[i][\"assembly_version\"].lower()][config_df.loc[j][\"assembly_version\"].lower()]\n                default_chainmap_name = \"chainmaps/\"+default_chainmap_path.split(\"/\")[-1]\n                chainmaps.append(default_chainmap_name)\n        config_df.at[i, 'chainmap'] = \",\".join(chainmaps)\nconfig_df"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Check config file"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Checking Config_file...\n\thg38ToMm10.over.chain.gz already exists.. Skipping\n\tmm10ToHg38.over.chain.gz already exists.. Skipping\nConfig_file is correct..\n"
    }
   ],
   "source": "print(\"Checking Config_file...\")\nfor i in config_df.index:\n    if not config_df.loc[i][\"assembly_version\"].lower() in dictionaries[\"chain_maps\"]:\n        print(\"'%s' is not a valid assembly_version. Please use one of the following values for default analysis: %s\"%(config_df.loc[i][\"assembly_version\"], \",\".join(dictionaries[\"chain_maps\"])))\n        sys.exit(1)\n    \n    defaults = config_df.loc[i][\"default\"].split(\"|\")\n    #Check GTFs and chainmaps\n    for feature,default in zip([\"annotation\",\"chainmap\"],defaults):\n        sp_vi = config_df.loc[i][\"assembly_version\"].lower()\n        if default == \"True\":\n            if feature == \"GTFs\": download_default_files(dictionaries[\"gtfs_ensembl_r98\"][sp_vi], \"GTFs\")\n            if feature == \"chainmap\":\n                for j in config_df.index:\n                    if i == j: continue\n                    sp_vj = config_df.loc[j][\"assembly_version\"].lower()\n                    url=dictionaries[\"chain_maps\"][sp_vi][sp_vj]\n                    download_default_files(url, \"chainmaps\")\n        else:\n            if feature == \"annotation\": check_file([config_df.loc[i][feature]])\n            if feature == \"chainmap\":   check_file(config_df.loc[i][feature].split(\",\"))\nprint(\"Config_file is correct..\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Download GTF files (if no gtf provided in config)"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Downloading GTFs\n\tNo default GTF needed for Human38.. Skipping\n\tNo default GTF needed for Mouse.. Skipping\n"
    }
   ],
   "source": "print('Downloading GTFs')\nfor i in config_df.index:\n    if config_df.loc[i][\"default\"].split(\"|\")[0] == \"False\": \n        print(\"\\tNo default GTF needed for %s.. Skipping\"%(i))\n        continue    \n    sp_v = config_df.loc[i][\"assembly_version\"].lower()\n    download_default_files(dictionaries[\"gtfs_ensembl_r98\"][sp_v], \"GTFs\")        "
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Download chainmaps"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Downloading default chainmaps...\n\thg38ToMm10.over.chain.gz already exists.. Skipping\n\tmm10ToHg38.over.chain.gz already exists.. Skipping\n"
    }
   ],
   "source": "print('Downloading default chainmaps...')\nfor i in config_df.index:\n    if config_df.loc[i][\"default\"].split(\"|\")[1] == \"True\":\n        sp_vi = config_df.loc[i][\"assembly_version\"].lower()\n        for j in config_df.index:\n            if i == j: continue\n            sp_vj = config_df.loc[j][\"assembly_version\"].lower()\n            url=dictionaries[\"chain_maps\"][sp_vi][sp_vj]\n            download_default_files(url, \"chainmaps\")\n    else:\n        print(\"\\tNo default chainmaps needed for %s.. Skipping\"%(i))"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Generate maps (transcriptID-geneID & geneID-geneName-geneType) "
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Generating transcriptID-geneID & geneID-geneName-geneType maps...\n\tGenerating map for Human38... done\n\tGenerating map for Mouse... done\n"
    }
   ],
   "source": "check_folder(\"maps\")\nprint(\"Generating transcriptID-geneID & geneID-geneName-geneType maps...\")\nfor i in config_df.index:\n    print(\"\\r\\tGenerating map for \"+i+\"...\", end=\"\")\n    gtf_file = config_df.loc[i][\"annotation\"]\n    sp_v = config_df.loc[i][\"assembly_version\"].lower()\n    if config_df.loc[i][\"default\"].split(\"|\")[0] == \"True\":\n        gtf_file = \"GTFs/\"+gtf_file\n    generate_maps(gtf_file, sp_v)\n    print(\"\\r\\tGenerating map for \"+i+\"... done\")"
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Transcripts map:\nENST00000456328.2\tENSG00000223972.5\tDDX11L1\ttranscribed_unprocessed_pseudogene\nENST00000450305.2\tENSG00000223972.5\tDDX11L1\ttranscribed_unprocessed_pseudogene\nENST00000488147.1\tENSG00000227232.5\tWASH7P\tunprocessed_pseudogene\nENST00000473358.1\tENSG00000243485.5\tMIR1302-2HG\tlncRNA\nENST00000469289.1\tENSG00000243485.5\tMIR1302-2HG\tlncRNA\n\nGenes map:\nENSG00000223972.5\tDDX11L1\ttranscribed_unprocessed_pseudogene\nENSG00000227232.5\tWASH7P\tunprocessed_pseudogene\nENSG00000243485.5\tMIR1302-2HG\tlncRNA\nENSG00000237613.2\tFAM138A\tlncRNA\nENSG00000268020.3\tOR4G4P\tunprocessed_pseudogene\n"
    }
   ],
   "source": "print(\"Transcripts map:\")\nwith open(\"maps/hg38.transcriptID_geneID_map.txt\") as transcripts:\n    head = [next(transcripts) for x in range(5)]\nfor l in head:\n    print(l.strip())\n\nprint(\"\\nGenes map:\")\nwith open(\"maps/hg38.geneID_geneName_geneType_map.txt\") as genes:\n    head = [next(genes) for x in range(5)]\nfor l in head:\n    print(l.strip())"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Generate BED with genes/exons from GTF files; sort & merge exons by gene"
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Generating BED files for exons and genes...\n\tGenerating BEDs for Human38... done\n\tGenerating BEDs for Mouse... done\n"
    }
   ],
   "source": "check_folder(\"BEDs\")\nprint(\"Generating BED files for exons and genes...\")\nfor i in config_df.index:\n    gtf_file = config_df.loc[i][\"annotation\"]\n    sp_v = config_df.loc[i][\"assembly_version\"].lower()\n    if config_df.loc[i][\"default\"].split(\"|\")[0] == \"Treu\":\n        gtf_file = \"GTFs/\"+gtf_file\n    print(\"\\r\\tGenerating BEDs for \"+i+\"...\", end=\"\")\n    generate_beds(gtf_file, sp_v)\n    print(\"\\r\\tGenerating BEDs for \"+i+\"... done\")"
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Sorting BED files...\n\t./BEDs/hg38.exons.bed... sorted \n\t./BEDs/hg38.genes.bed... sorted \n\t./BEDs/mm10.exons.bed... sorted \n\t./BEDs/mm10.genes.bed... sorted \n"
    }
   ],
   "source": "print(\"Sorting BED files...\")\nfor i in config_df.index:\n    sp_v = config_df.loc[i][\"assembly_version\"].lower()\n    bed_sort(sp_v)"
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Merging BED files...\n\t./BEDs/hg38.exons.bed... merged \n\t./BEDs/mm10.exons.bed... merged \n"
    }
   ],
   "source": "print(\"Merging BED files...\")\nfor i in config_df.index:\n    sp_v = config_df.loc[i][\"assembly_version\"].lower()\n    merge_bed(sp_v)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### LifOver exons/genes"
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "LiftOver...\n\tHuman38 exons to Mouse... done   \n\tHuman38 genes to Mouse... done   \n\tMouse exons to Human38... done   \n\tMouse genes to Human38... done   \n"
    }
   ],
   "source": "check_folder(\"liftovers\")\nfeatures = [\"exons\", \"genes\"]\nprint(\"LiftOver...\")\n\nfor i in config_df.index:\n    sp_vi = config_df.loc[i][\"assembly_version\"].lower()\n    chainmaps = config_df.loc[i][\"chainmap\"].split(\",\")\n    n=0\n    for j in config_df.index:\n        if i == j: continue\n        sp_vj = config_df.loc[j][\"assembly_version\"].lower()\n        map_chain = chainmaps[n] if config_df.loc[i][\"default\"] else chainmaps[n]\n        n+=1\n        #liftOver oldFile map.chain newFile unMapped\n        for feature in features:\n            print(\"\\r\\t{} {} to {}... mapping\".format(i, feature, j), end=\"\")\n            oldFile = \"BEDs/{}.{}.bed\".format(sp_vi, feature)\n            newFile = \"liftovers/{}to{}.{}.liftover\".format(sp_vi, sp_vj, feature)\n            unMapped= \"liftovers/{}to{}.{}.unmapped\".format(sp_vi, sp_vj, feature)\n            #print(\"./liftOver {} {} {} {}\".format(oldFile, map_chain, newFile, unMapped))\n            os.system(\"./scripts/liftOver -multiple -minMatch=0.{} {} {} {} {}\".format(minMatch, oldFile, map_chain, newFile, unMapped))\n            print(\"\\r\\t{} {} to {}... done   \".format(i, feature, j))"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Intersect LiftOvers"
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Intersecting LiftOver...\n\tHuman38 exons to Mouse... done         \n\tHuman38 genes to Mouse... done         \n\tMouse exons to Human38... done         \n\tMouse genes to Human38... done         \n"
    }
   ],
   "source": "check_folder(\"overlaps\")\nprint(\"Intersecting LiftOver...\")\nfor i in config_df.index:\n    for j in config_df.index:\n        if i == j: continue\n        for f in [\"exons\", \"genes\"]:\n            print(\"\\r\\t{} {} to {}... intersecting\".format(i, f, j), end=\"\")\n            sp1=config_df.loc[i][\"assembly_version\"].lower()\n            sp2=config_df.loc[j][\"assembly_version\"].lower()\n            lifover_input = 'liftovers/%sto%s.%s.liftover'%(sp1, sp2, f)\n            bed_input = 'BEDs/%s.%s.bed'%(sp2, f)\n            output = 'overlaps/%sto%s.%s.overlap'%(sp1, sp2, f)\n            call = 'intersectBed -wao -s -a %s -b %s > %s'%(lifover_input, bed_input, output)\n            subprocess.call(call, shell=True, executable='/bin/bash')\n            print(\"\\r\\t{} {} to {}... done         \".format(i, f, j))"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Parse Overlaps"
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Predicting orthologues...\n\tHuman38 exons to Mouse... done               \n\tHuman38 genes to Mouse... done               \n\tMouse exons to Human38... done               \n\tMouse genes to Human38... done               \n"
    }
   ],
   "source": "check_folder(\"orthology\")\nprint(\"Predicting orthologues...\")\n\nfor i in config_df.index:\n    for j in config_df.index:\n        \n        if i == j: continue\n        \n        sp1=config_df.loc[i][\"assembly_version\"].lower()\n        sp2=config_df.loc[j][\"assembly_version\"].lower() \n                   \n        # \"maps/hg38.transcriptID_geneID_map.txt\"\n        # ENST00000456328\tENSG00000223972\tDDX11L1\ttranscribed_unprocessed_pseudogene\n        # ENST00000450305\tENSG00000223972\tDDX11L1\ttranscribed_unprocessed_pseudogene\n        # ENST00000488147\tENSG00000227232\tWASH7P\tunprocessed_pseudogene\n        # ENST00000619216\tENSG00000278267\tMIR6859-1\tmiRNA\n        # ENST00000473358\tENSG00000243485\tMIR1302-2HG\tlncRNA\n\n        # \"maps/hg38.geneID_geneName_geneType_map.txt\"\n        # ENSG00000223972\tDDX11L1\ttranscribed_unprocessed_pseudogene\n        # ENSG00000227232\tWASH7P\tunprocessed_pseudogene\n        # ENSG00000278267\tMIR6859-1\tmiRNA\n        # ENSG00000243485\tMIR1302-2HG\tlncRNA\n        # ENSG00000284332\tMIR1302-2\tmiRNA\n        \n        genes = {}\n        sp1_tID_gID_Name_Type = transcript_map_to_dict('maps/%s.transcriptID_geneID_map.txt'%(sp1))\n        sp2_tID_gID_Name_Type = transcript_map_to_dict('maps/%s.transcriptID_geneID_map.txt'%(sp2))\n        \n        for f in [\"exons\", \"genes\"]:\n            print(\"\\r\\t{} {} to {}... finding orthologues\".format(i, f, j), end=\"\")\n            overlaps = \"overlaps/%sto%s.%s.overlap\"%(sp1, sp2, f)\n            for line in open(overlaps, 'r'):\n                \n                # read line overlap between sp1 and sp2\n                line = line.strip().split(\"\\t\")\n                geneA = line[3]\n                exonA = \",\".join([line[0], line[1], line[2]])\n                geneB = line[9]\n                exonB = \",\".join([line[6], line[7], line[8]]) \n\n                # calculate overlapping %\n                lA = int(line[2])-int(line[1]) #length geneA\n                lB = int(line[8])-int(line[7]) #length geneB\n                o = int(line[12])              #overlap\n\n                rA = (o*100)/lA                    #overlap of A to B\n                rB = 0 if lB == 0 else (o*100)/lB  #overlap of B to A\n\n                # Harmonic mean\n                try:\n                    hm = 2/((1/rA)+(1/rB))\n                except ZeroDivisionError:\n                    hm = 0\n                \n                # Gene_Name and Gene_Type\n                geneAtype = \"none\" if geneA == \".\" else sp1_tID_gID_Name_Type[geneA][\"gene_type\"]                \n                geneBtype = \"none\" if geneB == \".\" else sp2_tID_gID_Name_Type[geneB][\"gene_type\"]\n\n                # Add sp1 gene overlaps to dictionary\n                if not geneA in genes:\n                    genes[geneA] = {\"overlaps\": [],\n                                    \"genetype\": [],\n                                    \"geneAtype\": geneAtype,\n                                    \"exons\": {}}\n\n                if not geneB in genes[geneA][\"overlaps\"]:\n                    genes[geneA][\"overlaps\"].append(geneB)\n                    genes[geneA][\"genetype\"].append(geneBtype)\n\n                # Add sp1 exon overlaps to dictionary\n                if not exonA in genes[geneA][\"exons\"]:\n                    genes[geneA][\"exons\"][exonA] = {}\n\n                if not geneB in genes[geneA][\"exons\"][exonA]:\n                    genes[geneA][\"exons\"][exonA][geneB] = [rA, rB, hm]                    \n\n                # Update exonB if new exon have highr A>B overlap\n                # NOTE ---> and higher B>A overlap? change % of overlap with HM ??\n                if rA > genes[geneA][\"exons\"][exonA][geneB][0]:\n                    genes[geneA][\"exons\"][exonA][geneB] = [rA, rB, hm]                    \n                \n                \n            # Summarize overlaps into output\n            output_file = open('orthology/%sto%s.%s'%(sp1, sp2, f), \"w\")\n            for geneA in genes:\n                overlaps = genes[geneA][\"overlaps\"]\n                geneAtype = genes[geneA][\"geneAtype\"]\n                geneBtype = genes[geneA][\"genetype\"]\n                number_of_exons = []\n                percentageA = []\n                percentageB = []\n                for geneB in overlaps:\n                    n = 0\n                    mA, mB = 0, 0\n                    for exon in genes[geneA][\"exons\"]:\n                        if geneB in genes[geneA][\"exons\"][exon]:\n                            n+=1\n                            # %overlap A>B (rA)\n                            mA+=genes[geneA][\"exons\"][exon][geneB][0]\n                            mB+=genes[geneA][\"exons\"][exon][geneB][1]\n                    number_of_exons.append(str(n))\n                    percentageA.append(str(mA/n))\n                    percentageA.append(str(mB/n))\n                \n                percentageA = [ int(float(x)) for x in percentageA ]\n                percentageB = [ int(x) for x in percentageB ]\n                number_of_exons = [ int(x) for x in number_of_exons ]\n    \n                percentageA, number_of_exons, overlaps, geneBtype = zip(*sorted(zip(percentageA, number_of_exons, overlaps, geneBtype), reverse=True))\n                percentageA = [ str(x) for x in percentageA ]\n                number_of_exons = [ str(x) for x in number_of_exons ]\n                new_line = \"\\t\".join([geneA, geneAtype, \",\".join(overlaps), \",\".join(number_of_exons), \",\".join(percentageA), \",\".join(geneBtype)])\n                output_file.write(new_line+\"\\n\")\n            output_file.close()\n             \n            print(\"\\r\\t{} {} to {}... done               \".format(i, f, j))\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Add Unmapped exons/genes"
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Adding non-lifted genes...\n\tAdding non-lifted Human38 genes to results... done\n\tAdding non-lifted Mouse genes to results... done\n"
    }
   ],
   "source": "def BedToDict(sp1, feature, geneMap):\n    inFile = open(\"./BEDs/%s.%s.bed\"%(sp1, feature), 'r')\n    d = {}\n    for line in inFile:\n        line = line.strip().split(\"\\t\")\n        GeneName = line[3]\n        chrom = line[0]\n        start = line[1]\n        end = line[2]\n        strand = line[5]\n        gType = geneMap[GeneName][\"gene_type\"]\n        \n        if not GeneName in d:\n            d[GeneName] = [chrom, start, end, GeneName, \"0\", strand]\n    inFile.close()\n    return(d)\n\n\ndef OrthologyToList(sp1, sp2, feature):\n    inFile = open(\"./orthology/%sto%s.%s\"%(sp1, sp2, feature), 'r')\n    l = []\n    for line in inFile:\n        line = line.strip().split(\"\\t\")\n        GeneName = line[0]\n        l.append(GeneName)\n    inFile.close()\n    return(l)\n\nprint(\"Adding non-lifted genes...\")\nfor i in config_df.index:\n    for j in config_df.index:\n        \n        if i == j: continue\n        print(\"\\r\\tAdding non-lifted {} genes to results...\".format(i, f, j), end=\"\")\n        sp1=config_df.loc[i][\"assembly_version\"].lower()\n        sp2=config_df.loc[j][\"assembly_version\"].lower()\n        sp1_geneMap = gene_map_to_dict('maps/%s.geneID_geneName_geneType_map.txt'%(sp1))\n        \n        for f in [\"exons\", \"genes\"]:\n            d = BedToDict(sp1, f, sp1_geneMap)\n            l = OrthologyToList(sp1, sp2, f)\n            #print(\"before: \", len(d))\n            [d.pop(x) for x in l]\n            #print(\"after: \", len(d))\n            \n            fileName = \"./orthology/\"+sp1+\"to\"+sp2+\".\"+f\n            outFile = open(fileName, 'a')\n            for k in d:\n                info = d[k]\n                new_line = \"\\t\".join([k, info[3], \"-\", \"0\", \"0\", \"non_lifted\\n\"])\n                outFile.write(new_line)\n            outFile.close()\n        print(\"\\r\\tAdding non-lifted {} genes to results... done\".format(i, f, j))"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Classification"
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "non_lifted\nprotein_coding\nunitary_pseudogene\ntranscribed_unitary_pseudogene\nnone\ntranscribed_processed_pseudogene\nprocessed_pseudogene\ntranscribed_unprocessed_pseudogene\ntranslated_processed_pseudogene\nlncRNA\nunprocessed_pseudogene\npolymorphic_pseudogene\npseudogene\n"
    }
   ],
   "source": "for i in config_df.index:\n    for j in config_df.index:\n        \n        if i == j: continue\n    \n        sp1=config_df.loc[i][\"assembly_version\"].lower()\n        sp2=config_df.loc[j][\"assembly_version\"].lower()  \n        \n        exons_orthologs = \"orthology/{}to{}.exons\".format(sp1, sp2)\n        genes_orthologs = \"orthology/{}to{}.genes\".format(sp1, sp2)\n        h = []\n        for line in open(exons_orthologs, 'r'):\n            line=line.strip().split(\"\\t\")\n            bt = line[-1].split(\",\")\n            for e in bt:\n                if not e in h:\n                    h.append(e)\n    \nfor i in set(h):\n    print(i)"
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Classifying orthologues...\n\tHuman38 to Mouse... classifying\n\tHuman38 to Mouse... done       \n\tMouse to Human38... classifying\n\tMouse to Human38... done       \n"
    }
   ],
   "source": "##############################Biotypes##############################\n# non_lifted                          non_lifted\n# none                                none\n# lncRNA                              lncRNA\n# protein_coding                      pc\n# pseudogene                          pseudogene\n# unitary_pseudogene                  pseudogene\n# translated_processed_pseudogene     pseudogene\n# unprocessed_pseudogene              pseudogene\n# transcribed_unprocessed_pseudogene  pseudogene\n# transcribed_processed_pseudogene    pseudogene\n# transcribed_unitary_pseudogene      pseudogene\n# polymorphic_pseudogene              pseudogene\n# processed_pseudogene                pseudogene\n####################################################################\n\ncheck_folder(\"classification\")\nprint(\"Classifying orthologues...\")\n    \nfor i in config_df.index:\n    for j in config_df.index:\n        \n        if i == j: continue\n    \n        print(\"\\r\\t{} to {}... classifying\".format(i, j))\n        sp1=config_df.loc[i][\"assembly_version\"].lower()\n        sp2=config_df.loc[j][\"assembly_version\"].lower()  \n        output_file = open(\"classification/{}to{}.classification\".format(sp1, sp2), 'w')\n        \n        exons_orthologs = \"orthology/{}to{}.exons\".format(sp1, sp2)\n        genes_orthologs = \"orthology/{}to{}.genes\".format(sp1, sp2)\n\n        non_lifted = [\"non_lifted\"]\n        none = [\"none\"]\n        lncRNA = [\"lncRNA\"]\n        pc = [\"protein_coding\"]\n        pseudogene = [\"pseudogene\", \"unitary_pseudogene\", \"translated_processed_pseudogene\", \"unprocessed_pseudogene\", \"transcribed_unprocessed_pseudogene\", \"transcribed_processed_pseudogene\", \"transcribed_unitary_pseudogene\", \"polymorphic_pseudogene\", \"processed_pseudogene\"]\n\n        exons = {}\n        genes = {}\n\n        for line in open(exons_orthologs, 'r'):\n            line = line.strip().split(\"\\t\")\n            geneM, atype, ortho, nexon, pcent, btype = parse_orthologs(line)\n            \n            exon_counts = count_classes(btype)\n            exons[geneM] = [exon_counts, ortho, atype, btype]\n            \n        for line in open(genes_orthologs, 'r'):\n            line = line.strip().split(\"\\t\")\n            geneM, atype, ortho, nexon, pcent, btype = parse_orthologs(line)\n\n            gene_counts = count_classes(btype)\n            genes[geneM] = [gene_counts, ortho, atype, btype]\n      \n        for gene in exons:\n            e_atype = exons[gene][2]\n            e_btype = exons[gene][3]\n            e_counts = exons[gene][0]\n            e_ortho  = exons[gene][1]\n            exon_info = [e_atype, e_btype, e_counts, e_ortho]\n            try:\n                g_atype = genes[gene][2]\n                g_btype = genes[gene][3]\n                g_counts = genes[gene][0]\n                g_ortho = genes[gene][1]\n            except KeyError:\n                g_counts = \".\"\n                g_class_ = \".\"\n                g_ortho = \".\"\n            gene_info = [g_atype, g_btype, g_counts, g_ortho]             \n            prediction = classification_tree(exon_info, gene_info)\n\n            g_atype = \"pseudogene\" if \"pseudogene\" in g_atype else g_atype\n            output_file.write(\"{}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{}\".format(gene, g_atype, prediction, \";\".join(e_ortho), \";\".join(e_btype), e_counts, \";\".join(g_ortho), \";\".join(g_btype), g_counts)+\"\\n\")\n        output_file.close()\n        print(\"\\r\\t{} to {}... done       \".format(i, j))"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Plots"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "##### Plots v3"
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Plotting results...\n\tHuman38 to Mouse... plotting\n\tHuman38 to Mouse... done       \n\tMouse to Human38... plotting\n\tMouse to Human38... done       \n"
    }
   ],
   "source": "check_folder(\"plots\")\nprint(\"Plotting results...\")\n\nfor i in config_df.index:\n    for j in config_df.index:\n        if i == j: continue\n        print(\"\\r\\t{} to {}... plotting\".format(i, j))\n        sp1 = config_df.loc[i][\"assembly_version\"].lower()\n        sp2 = config_df.loc[j][\"assembly_version\"].lower() \n        call = 'Rscript ./scripts/alluvial_plots_v3.R %s %s'%(sp1, sp2)\n        subprocess.call(call, shell=True, executable='/bin/bash')\n        print(\"\\r\\t{} to {}... done       \".format(i, j))"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": ""
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
